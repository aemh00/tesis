{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%autosave 0\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import animation\n",
    "#from os.path import join\n",
    "#import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, cuda\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "#from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,confusion_matrix, classification_report\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../imbalanced_dataset_sampler/torchsampler/\")\n",
    "sys.path.append(\"../libs\")\n",
    "from vvv_utils import parse_metadata, parse_light_curve_data, plot_light_curve, get_train_test_ids\n",
    "#from imbalanced import ImbalancedDatasetSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88454 light curve metadata collected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P_ogle</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_VVV</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b221_201_22183</th>\n",
       "      <td>13.972335</td>\n",
       "      <td>6.986167</td>\n",
       "      <td>13.970992</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b221_205_41463</th>\n",
       "      <td>21.537799</td>\n",
       "      <td>10.770059</td>\n",
       "      <td>21.541892</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b232_614_24529</th>\n",
       "      <td>8.035356</td>\n",
       "      <td>16.069420</td>\n",
       "      <td>16.065114</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b233_201_30278</th>\n",
       "      <td>8.750438</td>\n",
       "      <td>4.374645</td>\n",
       "      <td>8.751487</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b233_201_16631</th>\n",
       "      <td>44.130627</td>\n",
       "      <td>22.070183</td>\n",
       "      <td>44.161985</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       P1         P2     P_ogle   label\n",
       "ID_VVV                                                 \n",
       "b221_201_22183  13.972335   6.986167  13.970992  binary\n",
       "b221_205_41463  21.537799  10.770059  21.541892  binary\n",
       "b232_614_24529   8.035356  16.069420  16.065114  binary\n",
       "b233_201_30278   8.750438   4.374645   8.751487  binary\n",
       "b233_201_16631  44.130627  22.070183  44.161985  binary"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_meta = parse_metadata(experiment=\"ALL\", merge_subclasses=True)\n",
    "class_names = df_meta[\"label\"].unique()\n",
    "display(df_meta.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_vvv = np.arange(len(df_meta))\n",
    "#indices_vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_VVV</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P_ogle</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b221_201_22183</td>\n",
       "      <td>13.972335</td>\n",
       "      <td>6.986167</td>\n",
       "      <td>13.970992</td>\n",
       "      <td>binary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b221_205_41463</td>\n",
       "      <td>21.537799</td>\n",
       "      <td>10.770059</td>\n",
       "      <td>21.541892</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b232_614_24529</td>\n",
       "      <td>8.035356</td>\n",
       "      <td>16.069420</td>\n",
       "      <td>16.065114</td>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b233_201_30278</td>\n",
       "      <td>8.750438</td>\n",
       "      <td>4.374645</td>\n",
       "      <td>8.751487</td>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b233_201_16631</td>\n",
       "      <td>44.130627</td>\n",
       "      <td>22.070183</td>\n",
       "      <td>44.161985</td>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88449</th>\n",
       "      <td>b395_201_28153</td>\n",
       "      <td>0.316792</td>\n",
       "      <td>0.633585</td>\n",
       "      <td>0.316787</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88450</th>\n",
       "      <td>b395_205_6265</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88451</th>\n",
       "      <td>b395_304_9934</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.711693</td>\n",
       "      <td>0.355842</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88452</th>\n",
       "      <td>b396_209_39823</td>\n",
       "      <td>0.814810</td>\n",
       "      <td>0.407405</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88453</th>\n",
       "      <td>b396_410_32500</td>\n",
       "      <td>0.313249</td>\n",
       "      <td>0.626496</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88454 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID_VVV         P1         P2     P_ogle    label    idx\n",
       "0      b221_201_22183  13.972335   6.986167  13.970992   binary      0\n",
       "1      b221_205_41463  21.537799  10.770059  21.541892   binary      1\n",
       "2      b232_614_24529   8.035356  16.069420  16.065114   binary      2\n",
       "3      b233_201_30278   8.750438   4.374645   8.751487   binary      3\n",
       "4      b233_201_16631  44.130627  22.070183  44.161985   binary      4\n",
       "...               ...        ...        ...        ...      ...    ...\n",
       "88449  b395_201_28153   0.316792   0.633585   0.316787  rrlyrae  88449\n",
       "88450   b395_205_6265   0.287350   0.574699   0.287350  rrlyrae  88450\n",
       "88451   b395_304_9934   0.355847   0.711693   0.355842  rrlyrae  88451\n",
       "88452  b396_209_39823   0.814810   0.407405   0.407412  rrlyrae  88452\n",
       "88453  b396_410_32500   0.313249   0.626496   0.313247  rrlyrae  88453\n",
       "\n",
       "[88454 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta[\"idx\"] = indices_vvv\n",
    "df_meta = df_meta.reset_index()\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_VVV</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P_ogle</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b221_201_22183</td>\n",
       "      <td>13.972335</td>\n",
       "      <td>6.986167</td>\n",
       "      <td>13.970992</td>\n",
       "      <td>binary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b221_205_41463</td>\n",
       "      <td>21.537799</td>\n",
       "      <td>10.770059</td>\n",
       "      <td>21.541892</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b232_614_24529</td>\n",
       "      <td>8.035356</td>\n",
       "      <td>16.069420</td>\n",
       "      <td>16.065114</td>\n",
       "      <td>binary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b233_201_30278</td>\n",
       "      <td>8.750438</td>\n",
       "      <td>4.374645</td>\n",
       "      <td>8.751487</td>\n",
       "      <td>binary</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b233_201_16631</td>\n",
       "      <td>44.130627</td>\n",
       "      <td>22.070183</td>\n",
       "      <td>44.161985</td>\n",
       "      <td>binary</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88449</th>\n",
       "      <td>b395_201_28153</td>\n",
       "      <td>0.316792</td>\n",
       "      <td>0.633585</td>\n",
       "      <td>0.316787</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88450</th>\n",
       "      <td>b395_205_6265</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88451</th>\n",
       "      <td>b395_304_9934</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.711693</td>\n",
       "      <td>0.355842</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88452</th>\n",
       "      <td>b396_209_39823</td>\n",
       "      <td>0.814810</td>\n",
       "      <td>0.407405</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88453</th>\n",
       "      <td>b396_410_32500</td>\n",
       "      <td>0.313249</td>\n",
       "      <td>0.626496</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>rrlyrae</td>\n",
       "      <td>88453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88454 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID_VVV         P1         P2     P_ogle    label    idx\n",
       "idx                                                                   \n",
       "0      b221_201_22183  13.972335   6.986167  13.970992   binary      0\n",
       "1      b221_205_41463  21.537799  10.770059  21.541892   binary      1\n",
       "2      b232_614_24529   8.035356  16.069420  16.065114   binary      2\n",
       "3      b233_201_30278   8.750438   4.374645   8.751487   binary      3\n",
       "4      b233_201_16631  44.130627  22.070183  44.161985   binary      4\n",
       "...               ...        ...        ...        ...      ...    ...\n",
       "88449  b395_201_28153   0.316792   0.633585   0.316787  rrlyrae  88449\n",
       "88450   b395_205_6265   0.287350   0.574699   0.287350  rrlyrae  88450\n",
       "88451   b395_304_9934   0.355847   0.711693   0.355842  rrlyrae  88451\n",
       "88452  b396_209_39823   0.814810   0.407405   0.407412  rrlyrae  88452\n",
       "88453  b396_410_32500   0.313249   0.626496   0.313247  rrlyrae  88453\n",
       "\n",
       "[88454 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_meta = df_meta[[\"idx\",\"ID_VVV\",\"P1\",\"P2\",\"P_ogle\",\"label\"]]\n",
    "df_meta = df_meta.set_index(df_meta[\"idx\"])\n",
    "df_meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiciones de Clases, Variables, Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_classes = {\"label\":{\"binary\":0, \"rrlyrae\":1, \"cepheid\":2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_VVV</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P_ogle</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b221_201_22183</td>\n",
       "      <td>13.972335</td>\n",
       "      <td>6.986167</td>\n",
       "      <td>13.970992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b221_205_41463</td>\n",
       "      <td>21.537799</td>\n",
       "      <td>10.770059</td>\n",
       "      <td>21.541892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b232_614_24529</td>\n",
       "      <td>8.035356</td>\n",
       "      <td>16.069420</td>\n",
       "      <td>16.065114</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b233_201_30278</td>\n",
       "      <td>8.750438</td>\n",
       "      <td>4.374645</td>\n",
       "      <td>8.751487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b233_201_16631</td>\n",
       "      <td>44.130627</td>\n",
       "      <td>22.070183</td>\n",
       "      <td>44.161985</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88449</th>\n",
       "      <td>b395_201_28153</td>\n",
       "      <td>0.316792</td>\n",
       "      <td>0.633585</td>\n",
       "      <td>0.316787</td>\n",
       "      <td>1</td>\n",
       "      <td>88449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88450</th>\n",
       "      <td>b395_205_6265</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>0.287350</td>\n",
       "      <td>1</td>\n",
       "      <td>88450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88451</th>\n",
       "      <td>b395_304_9934</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.711693</td>\n",
       "      <td>0.355842</td>\n",
       "      <td>1</td>\n",
       "      <td>88451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88452</th>\n",
       "      <td>b396_209_39823</td>\n",
       "      <td>0.814810</td>\n",
       "      <td>0.407405</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>1</td>\n",
       "      <td>88452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88453</th>\n",
       "      <td>b396_410_32500</td>\n",
       "      <td>0.313249</td>\n",
       "      <td>0.626496</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>1</td>\n",
       "      <td>88453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88454 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID_VVV         P1         P2     P_ogle  label    idx\n",
       "idx                                                                 \n",
       "0      b221_201_22183  13.972335   6.986167  13.970992      0      0\n",
       "1      b221_205_41463  21.537799  10.770059  21.541892      0      1\n",
       "2      b232_614_24529   8.035356  16.069420  16.065114      0      2\n",
       "3      b233_201_30278   8.750438   4.374645   8.751487      0      3\n",
       "4      b233_201_16631  44.130627  22.070183  44.161985      0      4\n",
       "...               ...        ...        ...        ...    ...    ...\n",
       "88449  b395_201_28153   0.316792   0.633585   0.316787      1  88449\n",
       "88450   b395_205_6265   0.287350   0.574699   0.287350      1  88450\n",
       "88451   b395_304_9934   0.355847   0.711693   0.355842      1  88451\n",
       "88452  b396_209_39823   0.814810   0.407405   0.407412      1  88452\n",
       "88453  b396_410_32500   0.313249   0.626496   0.313247      1  88453\n",
       "\n",
       "[88454 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable Categórica, reemplaza nombres por números\n",
    "df_meta.replace(lc_classes,inplace=True)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUEVO\n",
    "\n",
    "class LightCurve_Dataset(Dataset):\n",
    "    def __init__(self, df_metadata, transform=None):        \n",
    "        self.data = list()\n",
    "        self.name = df_metadata[\"ID_VVV\"]\n",
    "        self.period = df_metadata[\"P_ogle\"]\n",
    "        self.label = torch.from_numpy(df_metadata[\"label\"].values)\n",
    "        self.transform = transform\n",
    "        column_names_lc = [\"mjd\", \"mag\", \"err\"]\n",
    "        column_names_fill = [\"mjd\", \"mag\", \"err\", \"phase\", \"mask\"]\n",
    "        df_zeros = pd.DataFrame(np.zeros((1, 5)),columns=column_names_fill)\n",
    "        \n",
    "        for i in range(len(df_metadata)):\n",
    "            lc_data = parse_light_curve_data(self.name[i])\n",
    "            lc_data[\"phase\"] = np.mod(lc_data[\"mjd\"],self.period[i])/self.period[i]\n",
    "            #display(lc_data)\n",
    "            #normalize\n",
    "            mag_std = lc_data[\"mag\"].std()\n",
    "            lc_data[\"mjd\"] = lc_data[\"mjd\"]-lc_data[\"mjd\"].min()\n",
    "            lc_data[\"mag\"] = (lc_data[\"mag\"]-lc_data[\"mag\"].mean())/mag_std\n",
    "            lc_data[\"err\"] = lc_data[\"err\"]/mag_std\n",
    "            lc_data.sort_values(by=\"phase\", inplace=True)\n",
    "            # ajustar todas a largo 335, rellenando con 0s las que sean mas pequeñas,\n",
    "            # asignando un label '1' si es dato real y '0' si es dato rellenado.\n",
    "            \"\"\"if len(lc_data) == 335:\n",
    "                lc_data[\"mask\"] = 1\n",
    "            else:\n",
    "                while len(lc_data) < 335:\n",
    "                    #RELLENAR con 0s;\n",
    "                    lc_data = lc_data.append(df_zeros, ignore_index=True,sort=False)\n",
    "            lc_data = lc_data.fillna(1)\n",
    "            lc_data = lc_data[[\"phase\",\"mag\",\"err\",\"mjd\",\"mask\"]]\n",
    "            self.data.append(torch.from_numpy(lc_data.values.astype('float32')))\n",
    "            \"\"\"\n",
    "            lc_data = lc_data[[\"phase\",\"mag\",\"err\",\"mjd\"]]\n",
    "            lc_data_large = np.zeros(shape=(335, 5), dtype='float32')\n",
    "            lc_data_large[:lc_data.shape[0], :4] = lc_data.values\n",
    "            lc_data_large[:lc_data.shape[0], 4] = 1.\n",
    "            self.data.append(torch.from_numpy(lc_data_large))\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.data[idx], 'label': self.label[idx]}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def plot(self, idx, ax):\n",
    "        assert len(ax)==2, \"Needs two subaxis\"\n",
    "        ax[0].cla()  \n",
    "        ax[0].errorbar(self.data[idx][:, 0], self.data[idx][:, 1], self.data[idx][:, 2], fmt='.')\n",
    "        ax[0].invert_yaxis()\n",
    "        ax[1].cla()\n",
    "        ax[1].errorbar(self.data[idx][:, 3], self.data[idx][:, 1], self.data[idx][:, 2], fmt='.')\n",
    "        ax[1].invert_yaxis()\n",
    "        ax[0].set_title(\"%d %s %0.4f\" %(idx, self.name[idx],self.period[idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#para evaluar el tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "# CUIDADO, el parseo demora más de 1 hora y 45 min (me aburri de esperar). \n",
    "VVV = LightCurve_Dataset(df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VVV[420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# próxima ocasión CARGAR dataset desde pickle\n",
    "with open('/home/amorales/tesis/LC_test/pickles/newDataset_VVV.pkl', 'rb') as handle:\n",
    "    VVV = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar Dataset como Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/amorales/tesis/LC_test/pickles/newDataset_VVV.pkl', 'wb') as handle:\n",
    "    pickle.dump(VVV, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,1)\n",
    "VVV.plot(80000,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_max=0\n",
    "lc_min=np.inf\n",
    "for i in VVV:\n",
    "    if len(i['data'])>lc_max:\n",
    "        lc_max=len(i['data'])\n",
    "    if len(i['data'])<lc_min:\n",
    "        lc_min=len(i['data'])\n",
    "print(lc_min,lc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VVV[420]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phase = VVV[i]['data'][:,0]\n",
    "#mag = VVV[i]['data'][:,1]\n",
    "#err = VVV[i]['data'][:,2]\n",
    "#mask = VVV[i]['data'][:,4]\n",
    "#label = VVV[i]['label'].item()\n",
    "    # 0: Binary\n",
    "    # 1: RRL\n",
    "    # 2: Cepheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VVV_len = Counter(VVV[:]['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_Bin = (VVV[:]['label'].numpy() == 0).sum()\n",
    "n_RRL = (VVV[:]['label'].numpy() == 1).sum()\n",
    "n_Cep = (VVV[:]['label'].numpy() == 2).sum()\n",
    "VVV_len = np.array([n_Bin, n_RRL, n_Cep])\n",
    "VVV_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar Sampleo Random Manual Equitativo (EMRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class equal_manually_random(Dataset):    \n",
    "    def __init__(self, data, targets,transform=None):\n",
    "        assert torch.is_tensor(data)==True and torch.is_tensor(targets)==True\n",
    "        self.data=data\n",
    "        self.labels=targets\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRS_dataset(rs):\n",
    "    # Sampleo Random Manual NoEquitativo (NEMRS)\n",
    "    less_lc = VVV_len.min()\n",
    "    VVV_toy = list()\n",
    "    ant=0\n",
    "    for i,n_lc in enumerate(VVV_len):\n",
    "        if i==0:\n",
    "            rand_ind = np.random.permutation(np.arange(n_lc))[:less_lc*3]+ant\n",
    "        elif i==1:\n",
    "            rand_ind = np.random.permutation(np.arange(n_lc))[:less_lc*2]+ant\n",
    "        elif i==2:\n",
    "            rand_ind = np.random.permutation(np.arange(n_lc))[:less_lc]+ant\n",
    "        VVV_toy.append(rand_ind)\n",
    "        ant += n_lc\n",
    "    VVV_sameRandInd = np.concatenate(VVV_toy)\n",
    "    # Data filter\n",
    "    targets = [VVV[i]['label'].item() for i in VVV_sameRandInd]\n",
    "    targets = torch.tensor(targets,dtype=torch.long)\n",
    "    LC_magData = [VVV[i]['data'][:,1].numpy() for i in VVV_sameRandInd]\n",
    "    LC_errData = [VVV[i]['data'][:,2].numpy() for i in VVV_sameRandInd]\n",
    "    LC_mask = [VVV[i]['data'][:,4].numpy() for i in VVV_sameRandInd]\n",
    "    LC_magData = torch.tensor(LC_magData)\n",
    "    LC_errData = torch.tensor(LC_errData)\n",
    "    LC_mask = torch.tensor(LC_mask)\n",
    "    mag_err_mask=torch.stack((LC_magData,LC_errData,LC_mask),dim=1)\n",
    "    # Dataset\n",
    "    VVV_equalDataset = equal_manually_random(mag_err_mask, targets)\n",
    "    return VVV_equalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = get_train_test_ids(df_meta)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "display(Counter(list(df_meta.loc[train_idx][\"label\"])))\n",
    "display(Counter(list(df_meta.loc[test_idx][\"label\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloaders(dataset,use_IDS,split,train_size=32,test_size=64):\n",
    "    global train_idx\n",
    "    global test_idx\n",
    "    if use_IDS:\n",
    "        # ImbalancedDatasetSampler\n",
    "        #train_idx, valid_idx= train_test_split(\n",
    "        #                                np.arange(len(dataset)),\n",
    "        #                                test_size=split,\n",
    "        #                                shuffle=True,\n",
    "        #                                stratify=dataset[:]['label'])\n",
    "        #train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(dataset,\n",
    "                          sampler=ImbalancedDatasetSampler(dataset,\n",
    "                                                           indices=train_idx,\n",
    "                                                           callback_get_label= lambda dataset, idx:dataset[idx]['label'].item()),\n",
    "                          batch_size=train_size, shuffle=False)\n",
    "\n",
    "        test_loader= DataLoader(dataset,\n",
    "                                sampler=SubsetRandomSampler(test_idx),\n",
    "                                batch_size=test_size, shuffle=False)\n",
    "    else:\n",
    "        train_idx, valid_idx= train_test_split(\n",
    "                                        np.arange(len(dataset)),\n",
    "                                        test_size=split,\n",
    "                                        shuffle=True,\n",
    "                                        stratify=None)\n",
    "        train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(dataset,\n",
    "                                sampler=SubsetRandomSampler(train_idx),\n",
    "                                batch_size=train_size, shuffle=False)\n",
    "\n",
    "        test_loader = DataLoader(dataset,\n",
    "                                sampler=SubsetRandomSampler(valid_idx),\n",
    "                                batch_size=test_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def. Modelo NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacion adaptada a 1D de https://github.com/naoto0804/pytorch-inpainting-with-partial-conv\n",
    "\n",
    "class PartialConv(nn.Module):\n",
    "    def __init__(self, in_channels_C,in_channels_M, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(in_channels_C, out_channels, kernel_size,\n",
    "                                    stride, padding, dilation, groups, bias)\n",
    "        self.mask_conv = nn.Conv1d(in_channels_M, out_channels, kernel_size,\n",
    "                                   stride, padding, dilation, groups, False)\n",
    "        # self.input_conv.apply(weights_init('kaiming'))\n",
    "\n",
    "        torch.nn.init.constant_(self.mask_conv.weight, 1.0)\n",
    "\n",
    "        # mask is not updated\n",
    "        for param in self.mask_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self,input, mask):\n",
    "        # http://masc.cs.gmu.edu/wiki/partialconv\n",
    "        # C(X) = W^T * X + b, C(0) = b, D(M) = 1 * M + 0 = sum(M)\n",
    "        # W^T* (M .* X) / sum(M) + b = [C(M .* X) – C(0)] / D(M) + C(0)\n",
    "        #print(input.shape, mask.shape)\n",
    "        output = self.input_conv(input * mask)\n",
    "        if self.input_conv.bias is not None:\n",
    "            output_bias = self.input_conv.bias.view(1, -1, 1).expand_as(output)\n",
    "        else:\n",
    "            output_bias = torch.zeros_like(output)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_mask = self.mask_conv(mask)\n",
    "\n",
    "        no_update_holes = output_mask == 0\n",
    "        mask_sum = output_mask.masked_fill_(no_update_holes, 1.0)\n",
    "\n",
    "        output_pre = (output - output_bias) / mask_sum + output_bias\n",
    "        output = output_pre.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        new_mask = torch.ones_like(output)\n",
    "        new_mask = new_mask.masked_fill_(no_update_holes, 0.0)\n",
    "\n",
    "        return output, new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_gap(torch.nn.Module):\n",
    "    def __init__(self, in_channels_C=2,in_channels_M=1,c1=128,c2=64, c3=32, c4=16,c5=8, kernel_size=3, hid_dim=32,hid2_dim=16,hid3_dim=8,output_dim=5): \n",
    "        super(MLP_gap, self).__init__()\n",
    "        self.pconv1 = PartialConv(in_channels_C,in_channels_M, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        self.pconv2 = PartialConv(c4, c4, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        self.pconv3 = PartialConv(c4, c4, c2, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        #self.pconv4 = PartialConv(c4, c4, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        #self.pool1 = torch.nn.AvgPool1d(kernel_size, stride=None, padding=0,\n",
    "        #                                 ceil_mode=False, count_include_pad=True)\n",
    "        self.gap = torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.hidden1 = torch.nn.Linear(c2*1, hid_dim, bias=True)\n",
    "        self.hidden2 = torch.nn.Linear(hid_dim, hid2_dim, bias=True)\n",
    "        #self.hidden3 = torch.nn.Linear(hid2_dim, hid3_dim, bias=True)\n",
    "        self.output = torch.nn.Linear(hid2_dim, output_dim, bias=True)\n",
    "\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        #self.soft = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x,mask, t=0):\n",
    "        if t==1:\n",
    "            x = x.transpose(0,1)\n",
    "            mask = mask.transpose(0,1)\n",
    "        elif t==2:\n",
    "            #x = x.transpose(1,2)\n",
    "            mask = mask.transpose(1,2)\n",
    "    \n",
    "        x, mask = self.pconv1(x, mask)\n",
    "        x = self.activation(x)\n",
    "        x, mask = self.pconv2(x, mask)\n",
    "        x = self.activation(x)\n",
    "        x, mask = self.pconv3(x, mask)\n",
    "        x = self.activation(x)\n",
    "        #x, mask = self.pconv4(x, mask)\n",
    "        z = self.gap(x)\n",
    "        z = z.reshape(-1,64*1)\n",
    "        z = self.activation(self.hidden1(z))\n",
    "        z = self.activation(self.hidden2(z))\n",
    "        #z = self.activation(self.hidden3(z))\n",
    "        fuera = self.output(z)\n",
    "        return fuera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_last(torch.nn.Module):\n",
    "    def __init__(self, in_channels_C=2,in_channels_M=1,c1=128,c2=64, c3=32, c4=16,c5=8, kernel_size=3, hid_dim=32,hid2_dim=16,hid3_dim=8,output_dim=3): \n",
    "        super(MLP_last, self).__init__()\n",
    "        self.pconv1 = PartialConv(in_channels_C,in_channels_M, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        self.pconv2 = PartialConv(c4, c4, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        self.pconv3 = PartialConv(c4, c4, c2, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        #self.pconv4 = PartialConv(c4, c4, c4, kernel_size, stride=2, padding=0, dilation=1, bias=True)\n",
    "        #self.pool1 = torch.nn.AvgPool1d(kernel_size, stride=None, padding=0,\n",
    "        #                                 ceil_mode=False, count_include_pad=True)\n",
    "        self.gap = torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.hidden1 = torch.nn.Linear(c2*1, hid_dim, bias=True)\n",
    "        self.hidden2 = torch.nn.Linear(hid_dim, hid2_dim, bias=True)\n",
    "        #self.hidden3 = torch.nn.Linear(hid2_dim, hid3_dim, bias=True)\n",
    "        self.output = torch.nn.Linear(hid2_dim, output_dim, bias=True)\n",
    "\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        #self.soft = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x,mask, t=0):\n",
    "        if t==1:\n",
    "            x = x.transpose(0,1)\n",
    "            mask = mask.transpose(0,1)\n",
    "        elif t==2:\n",
    "            #x = x.transpose(1,2)\n",
    "            mask = mask.transpose(1,2)\n",
    "    \n",
    "        x, mask = self.pconv1(x, mask)\n",
    "        x = self.activation(x)\n",
    "        x, mask = self.pconv2(x, mask)\n",
    "        x = self.activation(x)\n",
    "        x, mask = self.pconv3(x, mask)\n",
    "        x = self.activation(x)\n",
    "        #x, mask = self.pconv4(x, mask)\n",
    "        z = self.gap(x)\n",
    "        z = z.reshape(-1,64*1)\n",
    "        z = self.activation(self.hidden1(z))\n",
    "        z = self.activation(self.hidden2(z))\n",
    "        #z = self.activation(self.hidden3(z))\n",
    "        fuera = self.output(z)\n",
    "        return fuera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MLP_last()\n",
    "display(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in modelo.parameters() if p.requires_grad)\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BetaTesting-b4-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(ax,TL,VL,F1,last_ep,best_f1,topf1_logs):\n",
    "    #global comentario\n",
    "    titulo=\"Current Training: Sample=\"+str(s)\n",
    "    [ax_.cla() for ax_ in ax]\n",
    "    ax[0].plot(range(len(TL)), TL, lw=2, label='Train')\n",
    "    ax[0].plot(range(len(VL)), VL, lw=2, label='Valid')\n",
    "    ax[0].axvline(last_ep,c='r',marker='|',lw=1,label=\"Last improve\")\n",
    "    ax[0].plot(range(len(VL)),np.full_like(VL,min(VL)),'r--',lw=1, label='best VL')\n",
    "    ax[1].plot(range(len(F1)), F1, lw=2, label='F1 score')\n",
    "    if len(topf1_logs)==0:\n",
    "        # plot topf1 actual\n",
    "        ax[1].plot(range(len(F1)),np.full_like(F1,best_f1),'r--',lw=1, label='top F1')\n",
    "        \n",
    "    else:\n",
    "        # plot topf1 mean\n",
    "        ax[1].plot(range(len(F1)),np.full_like(F1,best_f1),'r--',lw=1, label='top F1')\n",
    "        ax[1].plot(range(len(F1)),np.full_like(F1,np.mean(topf1_logs)),'g--',lw=1, label='mean F1')\n",
    "    [ax_.set_xlabel('Epochs') for ax_ in ax]\n",
    "    [ax_.grid() for ax_ in ax]\n",
    "    [ax_.legend() for ax_ in ax]\n",
    "    fig.suptitle(titulo)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phase = VVV[i]['data'][:,0]\n",
    "#mag = VVV[i]['data'][:,1]\n",
    "#err = VVV[i]['data'][:,2]\n",
    "#mask = VVV[i]['data'][:,4]\n",
    "#label = VVV[i]['label'].item()\n",
    "    # 0: Binary\n",
    "    # 1: RRL\n",
    "    # 2: Cepheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(modelo, criterion, lr,wd, epochs, use_gpu, train_loader, test_loader,path,ax,topf1_logs):\n",
    "    optimizer = torch.optim.Adam(modelo.parameters(), lr=lr,weight_decay=wd)\n",
    "    ultima_mejora = 0\n",
    "    best_valid,best_f1= np.inf,0.0\n",
    "    TL,VL,F1=list(),list(),list()\n",
    "\n",
    "    for k in epochs:\n",
    "        if k-ultima_mejora >=300:\n",
    "            print(\"Hace al menos 300 épocas NO disminuye Valid Loss. Best F1=\",best_f1)\n",
    "            break\n",
    "        train_loss, valid_loss,f1_acum = 0.0, 0.0, 0.0\n",
    "        # Loop de entrenamiento\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch['data'],batch['label']\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            inputs = inputs.transpose(1,2)\n",
    "            #display(inputs.shape,labels.shape)\n",
    "            #break\n",
    "            data,mask = inputs[:,[1,2]],inputs[:,4].unsqueeze(0).transpose(0,1)\n",
    "            #display(data.shape,mask.shape)\n",
    "            #display(data,mask)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = modelo.forward(data,mask,t=0)\n",
    "            #display(outputs.shape,labels.shape)\n",
    "            #break\n",
    "            loss = criterion(outputs,labels)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        TL.append(train_loss/train_loader.__len__()) \n",
    "\n",
    "        # VALIDACION \n",
    "        for batch in test_loader:\n",
    "            inputs, labels = batch['data'],batch['label']\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            inputs = inputs.transpose(1,2)\n",
    "            #display(inputs.shape,labels.shape)\n",
    "            data,mask = inputs[:,[1,2]],inputs[:,4].unsqueeze(0).transpose(0,1)\n",
    "            \n",
    "            y_true=labels.cpu().numpy()\n",
    "            #display(y_true)\n",
    "            #break\n",
    "            outputs = modelo.forward(data,mask,t=0)\n",
    "            # F1 score\n",
    "            y_pred=outputs.cpu().detach().argmax(dim=1).numpy()\n",
    "            #print(y_pred)\n",
    "            f1_acum += f1_score(y_true, y_pred, average='weighted')\n",
    "            loss = criterion(outputs,labels)\n",
    "            #print(loss.item())\n",
    "            valid_loss += loss.item()\n",
    "            #print(valid_loss)\n",
    "            # save best model\n",
    "        if valid_loss < best_valid:\n",
    "            ultima_mejora = k+1\n",
    "            #print(\"vamos mejorando :) epoch=\",k+1)\n",
    "            best_valid = valid_loss\n",
    "            best_f1 = f1_acum/test_loader.__len__()\n",
    "            torch.save({'epoca': k,\n",
    "                        'f1_score': best_f1,\n",
    "                        'model_state_dict': modelo.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'Valid_loss': valid_loss/test_loader.__len__()}, path)\n",
    "        VL.append(valid_loss/test_loader.__len__())\n",
    "        F1.append(f1_acum/test_loader.__len__())\n",
    "        update_plot(ax,TL,VL,F1,ultima_mejora,best_f1,topf1_logs)\n",
    "\n",
    "    # Retornar modelo a la CPU\n",
    "    if use_gpu:\n",
    "        modelo = modelo.cpu()\n",
    "        #print(\"ok\")\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros generales\n",
    "n_epochs=10000\n",
    "lr=0.0002\n",
    "wd = 0\n",
    "epochs = range(n_epochs)\n",
    "use_gpu = True\n",
    "use_IDS = True\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "semilla=774892200\n",
    "rs=RandomState(semilla)\n",
    "split,train_size,test_size=0.3,32,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# New Dataset\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8.5, 4), tight_layout=True, sharex=True)\n",
    "top5f1=list()\n",
    "prompt=\"Training new Dataset\"\n",
    "print(\"\\nBegin\",prompt)\n",
    "for s in range(5): \n",
    "    comentario = \"_sample\"+str(s)\n",
    "    path = '/home/amorales/tesis/LC_test/models/LCC_newDataset_model_01_'+comentario+'.pt'\n",
    "    # DataLoaders\n",
    "    train_loader, test_loader = make_dataloaders(VVV,use_IDS,split,train_size,test_size)\n",
    "    # ENTRENAR\n",
    "    modelo=MLP_last()\n",
    "    if use_gpu:\n",
    "        modelo=modelo.cuda()\n",
    "    topf1 = training(modelo, criterion, lr,wd, epochs, use_gpu, train_loader, test_loader,path,ax,top5f1)\n",
    "    top5f1.append(topf1)\n",
    "\n",
    "# return f1 mean, f1 std\n",
    "print(\"Results: F1 mean=\",np.mean(top5f1),\"F1 std=\",np.std(top5f1))\n",
    "print(\"End\",prompt)\n",
    "print(\"-------END-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original práctica\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8.5, 4), tight_layout=True, sharex=True)\n",
    "# for IDS in [0,1]:\n",
    "for rot_key in [0,1]:\n",
    "    for alpha in [0,0.25,0.5,0.75,1]:\n",
    "        top5f1=list()\n",
    "        prompt=\"Training. Rot=\"+str(rot_key)+\", Alpha=\"+str(alpha)\n",
    "        print(\"\\nBegin\",prompt)\n",
    "        for s in range(5): \n",
    "            comentario = \"_Rot\"+str(rot_key)+\"_Alpha\"+str(alpha)+\"_sampleo\"+str(s)\n",
    "            path = '/home/amorales/models/best_LCC_model_last_'+comentario+'.pt'\n",
    "            # sampleo random manual y crear dataset\n",
    "            VVV_eqData=MRS_dataset(rs)\n",
    "            # DataLoaders\n",
    "            train_loader, test_loader = make_dataloaders(VVV_eqData,use_IDS,split,train_size,test_size)\n",
    "            # ENTRENAR\n",
    "            modelo=MLP_last()\n",
    "            if use_gpu:\n",
    "                modelo=modelo.cuda()\n",
    "            topf1 = training(modelo, criterion, lr,wd, epochs, use_gpu, train_loader, test_loader,path,ax,top5f1)\n",
    "            top5f1.append(topf1)\n",
    "        \n",
    "        # return f1 mean, f1 std\n",
    "        print(\"Results: F1 mean=\",np.mean(top5f1),\"F1 std=\",np.std(top5f1))\n",
    "        print(\"End\",prompt)\n",
    "print(\"-------END-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matriz de Confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "besto = MLP()\n",
    "PATH = '/home/amorales/tesis/models/best_LCC_model_dataRot0_Alpha1_sampleo4.pt'\n",
    "besto.load_state_dict(torch.load(PATH)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Junio 2020\n",
    "besto = MLP_last()\n",
    "PATH = '/home/amorales/tesis/models/best_LCC_model_dataRot0_Alpha1_sampleo4.pt'\n",
    "besto.load_state_dict(torch.load(path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFICADA New Dataset ()\n",
    "#y_true = [best_of_best[i]['label'].item() for i in range(len(best_of_best))]\n",
    "#y_true = [VVV[i]['label'].item() for i in valid_idx]\n",
    "\n",
    "prediction_test = []\n",
    "labels_test=[]\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch['data'],batch['label']\n",
    "    inputs = inputs.transpose(1,2)\n",
    "    #display(inputs.shape,labels.shape)\n",
    "    data,mask = inputs[:,[1,2]],inputs[:,4].unsqueeze(0).transpose(0,1)\n",
    "    labels_test.append(labels.detach().numpy())\n",
    "    #y_true=labels.cpu().numpy()\n",
    "    #display(y_true)\n",
    "    #break\n",
    "    outputs = besto.forward(data,mask,t=0)\n",
    "    # F1 score\n",
    "    y_pred=outputs.detach().argmax(dim=1).numpy()\n",
    "    #print(outputs)\n",
    "    prediction_test.append(outputs.detach().argmax(dim=1).numpy())\n",
    "y_true = np.concatenate(labels_test)\n",
    "y_pred = np.concatenate(prediction_test)\n",
    "print(y_pred.__len__()/5)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "display(cm)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFICAR\n",
    "#y_true = [best_of_best[i]['label'].item() for i in range(len(best_of_best))]\n",
    "#y_true = [VVV[i]['label'].item() for i in valid_idx]\n",
    "\n",
    "prediction_test = []\n",
    "labels_test=[]\n",
    "for data in test_loader:\n",
    "    inputs, labels = data['data'],data['label']\n",
    "    data,mask = inputs[:,:2],inputs[:,2].unsqueeze(-1)\n",
    "    labels_test.append(labels.detach().numpy())\n",
    "    outputs = besto.forward(data,mask,t=2)\n",
    "    #logits = modelo.forward(sample_data)\n",
    "    #print(outputs)\n",
    "    prediction_test.append(outputs.detach().argmax(dim=1).numpy())\n",
    "y_true = np.concatenate(labels_test)\n",
    "y_pred = np.concatenate(prediction_test)\n",
    "print(y_pred.__len__()/5)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "display(cm)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre distintos Modelos\n",
    "Historial Matrices de Confusion [https://docs.google.com/spreadsheets/d/1j9kseGSx1WQvkb1C4nDL5J-lweuH3VyPsrAT50E1D6w/edit#gid=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lc_debug.pkl', 'rb') as handle:\n",
    "    lc_debug = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= '/home/amorales/models/best_LCC_model_NoPool__Rot1_Alpha1_sampleo1.pt'\n",
    "path0= '/home/amorales/models/best_LCC_model__Rot1_Alpha1_sampleo0.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "besto0,besto1 = MLP_(),MLP()\n",
    "#PATH = '/home/amorales/models/best_LCC_model_dataRot0_Alpha1_sampleo4.pt'\n",
    "besto0.load_state_dict(torch.load(path0)['model_state_dict'])\n",
    "besto1.load_state_dict(torch.load(path1)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pond=2.3\n",
    "fig1, ax1 = plt.subplots(6, 4, figsize=(4*pond, 6*pond), tight_layout=True,sharey=True,sharex=False)\n",
    "fig2, ax2 = plt.subplots(6, 4, figsize=(4*pond, 6*pond), tight_layout=True,sharey=True,sharex=True)\n",
    "fig1.suptitle(\"Modelo sin Activacion\")\n",
    "fig2.suptitle(\"Modelo con Activacion, sin Pooling\")\n",
    "for i,lc in enumerate(lc_debug):\n",
    "    data,label=lc['data'],lc['label']\n",
    "    n = sum(data[:,4]==1).item()\n",
    "    print(n)\n",
    "    pha = data[:,0]\n",
    "    mag = data[:,1]\n",
    "    err = data[:,2]\n",
    "    data2=torch.stack((mag,err))\n",
    "    data,mask = data2.unsqueeze(0),data[:,4].unsqueeze(-1).unsqueeze(0).transpose(1,2)\n",
    "    #data,mask = data[:,:2].unsqueeze(0).transpose(1,2),data[:,4].unsqueeze(0).unsqueeze(-1).transpose(1,2)\n",
    "    norm = Normalize(0,1,clip=False)\n",
    "    for j in range(4):\n",
    "        if i<3:\n",
    "            star=\"ECL\"\n",
    "        else:\n",
    "            star=\"RRL\"\n",
    "        if j!=3:\n",
    "            layer=\"Conv \"+str(j+1)\n",
    "        else:\n",
    "            layer=\"GAP\"\n",
    "        if j==0:\n",
    "            data0,mask0=besto0.pconv1(data,mask)\n",
    "            data1,mask1=besto1.pconv1(data,mask)\n",
    "            data1=besto1.activation(data1)\n",
    "\n",
    "        elif j==1:\n",
    "            data0,mask0=besto0.pconv2(data0,mask0)\n",
    "            data1,mask1=besto1.pconv2(data1,mask1)\n",
    "            data1=besto1.activation(data1)\n",
    "\n",
    "        elif j==2:\n",
    "            data0,mask0=besto0.pconv3(data0,mask0)\n",
    "            data1,mask1=besto1.pconv3(data1,mask1)\n",
    "            data1=besto1.activation(data1)\n",
    "\n",
    "        else:       \n",
    "            mask0_tmp=mask0.squeeze()[0].numpy().astype('int32')\n",
    "            mask1_tmp=mask1.squeeze()[0].numpy().astype('int32')\n",
    "            m0,m1= sum(mask0_tmp),sum(mask1_tmp)\n",
    "            print(m0,m1)\n",
    "            data0_tmp=data0.squeeze().detach()\n",
    "            data1_tmp=data1.squeeze().detach()\n",
    "            data0_slice=data0_tmp[:,:m0].unsqueeze(0)\n",
    "            data1_slice=data1_tmp[:,:m1].unsqueeze(0)\n",
    "            \"\"\"mask0_tmp=mask0.bool()\n",
    "            data0_slice=data0[mask0_tmp]\n",
    "            mask1_tmp=mask1.bool()\n",
    "            data1_slice=data1[mask1_tmp]\n",
    "            display(mask1_tmp.shape,data1_slice.shape)\"\"\"\n",
    "            data0=besto0.gap(data0_slice)\n",
    "            data1=besto1.gap(data1_slice)\n",
    "            display(data0.shape,data1.shape)\n",
    "        #plot\n",
    "        #ax1[i][j].errorbar(pha,mag,err, fmt='b.')\n",
    "        #ax2[i][j].errorbar(pha,mag,err, fmt='b.')\n",
    "        filtro0=data0.squeeze().detach().numpy()\n",
    "        filtro1=data1.squeeze().detach().numpy()\n",
    "        ax1[i][j].imshow(filtro0,norm=norm,cmap='plasma')\n",
    "        ax2[i][j].imshow(filtro1,norm=None)\n",
    "        ax1[i][j].set_title(star+\" after \"+layer+\", n= \"+str(n))\n",
    "        ax2[i][j].set_title(star+\" after \"+layer+\", n= \"+str(n))\n",
    "        if i==0 and j==0:\n",
    "            ax1[i][j].invert_yaxis()\n",
    "            ax2[i][j].invert_yaxis()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.repeat_interleave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.from_numpy(np.random.random(100))\n",
    "y_rp = y.repeat_interleave(2,dim=0)\n",
    "display(y,y_rp,y.shape,y_rp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pond=2\n",
    "#fig, ax = plt.subplots(4, 2, figsize=(4*pond, 6*pond), tight_layout=False)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8.5, 4), tight_layout=True, sharex=False)\n",
    "data=lc_debug[1]['data']\n",
    "n = sum(data[:,4]==1).item()\n",
    "print(n)\n",
    "mag = data[:,1]\n",
    "err = data[:,2]\n",
    "data2=torch.stack((mag,err))\n",
    "data,mask = data2.unsqueeze(0),data[:,4].unsqueeze(-1).unsqueeze(0).transpose(1,2)\n",
    "data1,mask1=besto0.pconv1(data,mask)\n",
    "mask_tmp=mask1.squeeze()[0].numpy().astype('int32')\n",
    "m= sum(mask_tmp)\n",
    "print(m)\n",
    "data_tmp=data1.squeeze().detach()\n",
    "data_slice=data_tmp[:,:m]\n",
    "data_repeat=data_slice.repeat_interleave(2,dim=1)[:,:-1]\n",
    "display(data_repeat.shape,data_slice.shape)\n",
    "ax[0].imshow(data_repeat)\n",
    "ax[1].imshow(data_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astro",
   "language": "python",
   "name": "astro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
